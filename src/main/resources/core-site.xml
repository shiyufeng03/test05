<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Licensed under the Apache License, Version 2.0 (the "License"); you 
may not use this file except in compliance with the License. You may obtain 
a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless 
required by applicable law or agreed to in writing, software distributed 
under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES 
OR CONDITIONS OF ANY KIND, either express or implied. See the License for 
the specific language governing permissions and limitations under the License. 
See accompanying LICENSE file. -->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://dev-namenode:9000/</value>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/home/pplive/data/hadoop/tmp</value>
	</property>
	<property>
		<name>io.file.buffer.size</name>
		<value>65536</value>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.dir</name>
		<value>/home/pplive/hard_disk/1,/home/pplive/hard_disk/nfsbackup</value>
	</property>
	<property>
		<name>hadoop.native.lib</name>
		<value>true</value>
		<description>Should native hadoop libraries, if present, be used.
		</description>
	</property>
	<property>
		<name>fs.trash.interval</name>
		<value>10080</value>
		<description>Number of minutes between trash checkpoints. If zero, the
			trash feature is disabled.  </description>
	</property>
	<!--
	<property>
		<name>io.compression.codecs</name>
		<value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec</value>
	</property>
	<property>
		<name>io.compression.codec.lzo.class</name>
		<value>com.hadoop.compression.lzo.LzoCodec</value>
	</property>
	-->
	<property>
		<name>io.file.buffer.size</name>
		<value>65536</value>
	</property>
	<property>
		<name>hadoop.proxyuser.pplive.hosts</name>
		<value>*</value>
	</property>
	<property>
		<name>hadoop.proxyuser.pplive.groups</name>
		<value>*</value>
	</property>
	<property>
		<name>topology.script.file.name</name>
		<value>/home/pplive/platform/config/hadoop/rack_info</value>
	</property>

	<property>
 		 <name>hadoop.security.group.mapping</name>
		 <value>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</value>
	         <description>
		    Class for user to group mapping (get groups for a given user) for ACL.
		    The default implementation,
    			org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback,
 		    will determine if the Java Native Interface (JNI) is available. If JNI is
		    available the implementation will use the API within hadoop to resolve a
 		   list of groups for a user. If JNI is not available then the shell
   		   implementation, ShellBasedUnixGroupsMapping, is used.  This implementation
   			 shells out to the Linux/Unix environment with the
    		<code>bash -c groups</code> command to resolve a list of groups for a user.
  		</description>
	</property>
</configuration>
